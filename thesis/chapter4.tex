%!TEX root = 1.main.tex
\chapter{Results and Discussion}
\label{cha:results}

This chapter presents the testing methodology, evaluation results, and analysis of MalGuard's performance. We examine functional testing outcomes, performance benchmarks, detection accuracy, cross-platform compatibility, and comparison with existing solutions.

\section{Testing Environment}

\subsection{Hardware Specifications}

Testing was conducted on the following hardware configurations:

\begin{table}[h]
\centering
\caption{Testing Hardware Specifications}
\label{tab:hardware}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Component} & \textbf{Primary System} & \textbf{Secondary System} \\
\midrule
Operating System & Windows 11 Pro & Ubuntu 22.04 LTS \\
Processor & Intel Core i7-12700H & AMD Ryzen 5 5600X \\
RAM & 16 GB DDR5 & 32 GB DDR4 \\
Storage & 512 GB NVMe SSD & 1 TB NVMe SSD \\
Network & Gigabit Ethernet & Gigabit Ethernet \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Software Configuration}

The testing environment utilized the following software versions:

\begin{table}[h]
\centering
\caption{Software Versions Used in Testing}
\label{tab:software}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Software} & \textbf{Version} & \textbf{Component} \\
\midrule
Python & 3.11.5 & Desktop CLI, Backend \\
Node.js & 18.18.0 & Web, Mobile \\
FastAPI & 0.104.0 & Backend \\
React & 18.2.0 & Web Frontend \\
React Native & 0.72.0 & Mobile App \\
Expo SDK & 49.0.0 & Mobile App \\
SQLite & 3.43.0 & Database \\
YARA & 4.3.2 & Pattern Matching \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Test Data}

Testing utilized both synthetic and real-world data:

\begin{itemize}
    \item \textbf{EICAR Test Files:} Standard antivirus test files for detection verification \cite{eicar2003}
    \item \textbf{Sample Signatures:} 25 pre-loaded malware signatures (trojans, ransomware, worms)
    \item \textbf{YARA Rules:} 8 custom detection rules
    \item \textbf{Clean Files:} Various legitimate executables and documents
    \item \textbf{Directory Structures:} Test directories with 100-10,000 files
\end{itemize}

\section{Functional Testing}

\subsection{EICAR Test File Detection}

The EICAR test file is an industry-standard method for verifying antivirus scanner functionality \cite{eicar2003}. MalGuard was tested with all variants:

\begin{table}[h]
\centering
\caption{EICAR Test File Detection Results}
\label{tab:eicar}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Test File} & \textbf{Hash Type} & \textbf{Detected} & \textbf{Time (ms)} \\
\midrule
eicar.txt & SHA-256 & \checkmark & 12 \\
eicar.com & SHA-256 & \checkmark & 11 \\
eicar\_com.zip & SHA-256 & \checkmark & 15 \\
eicar\_com2.zip & SHA-256 & \checkmark & 18 \\
\bottomrule
\end{tabular}
\end{table}

The EICAR test file with SHA-256 hash:

\begin{verbatim}
275a021bbfb6489e54d471899f7db9d1663fc695ec2fe2a2c4538aabf651fd0f
\end{verbatim}

Was correctly identified and flagged as ``EICAR-Test-File'' with appropriate severity classification.

\subsection{Signature Management Testing}

All signature CRUD operations were verified:

\begin{table}[h]
\centering
\caption{Signature Management Test Results}
\label{tab:sig_tests}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Operation} & \textbf{Result} & \textbf{Notes} \\
\midrule
Add signature & Pass & HMAC updated correctly \\
Remove signature & Pass & Verified removal from DB \\
List signatures & Pass & Pagination working \\
Search signatures & Pass & Name and hash search functional \\
Filter by severity & Pass & All severity levels filter correctly \\
Import from JSON & Pass & 25 signatures imported \\
Export to JSON & Pass & Valid JSON generated \\
Bulk import & Pass & Duplicate detection working \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Quarantine System Testing}

The quarantine functionality was tested for all operations:

\begin{table}[h]
\centering
\caption{Quarantine System Test Results}
\label{tab:quarantine_tests}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Operation} & \textbf{Result} & \textbf{Notes} \\
\midrule
Quarantine file & Pass & File moved, manifest updated \\
List quarantine & Pass & All metadata displayed \\
Restore file & Pass & File restored to original location \\
Restore to custom path & Pass & Custom destination working \\
Delete from quarantine & Pass & File and entry removed \\
Clear all quarantine & Pass & All files deleted \\
\bottomrule
\end{tabular}
\end{table}

\subsection{API Endpoint Testing}

All backend API endpoints were tested using automated and manual methods:

\begin{table}[h]
\centering
\caption{API Endpoint Test Results}
\label{tab:api_tests}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Endpoint} & \textbf{Method} & \textbf{Status} & \textbf{Response (ms)} \\
\midrule
/health & GET & Pass & 8 \\
/info & GET & Pass & 12 \\
/scan/file & POST & Pass & 45 \\
/scan/files & POST & Pass & 120 \\
/scan/hash & POST & Pass & 15 \\
/signatures & GET & Pass & 25 \\
/signatures & POST & Pass & 18 \\
/signatures/search & GET & Pass & 22 \\
/signatures/bulk & POST & Pass & 85 \\
/history & GET & Pass & 30 \\
/stats & GET & Pass & 20 \\
/quarantine & GET & Pass & 18 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{HMAC Integrity Verification}

The HMAC protection mechanism was tested for tamper detection:

\begin{enumerate}
    \item \textbf{Normal Operation:} Database loads successfully with valid HMAC
    \item \textbf{Modified Data:} Manually altered signature entry---correctly rejected with integrity error
    \item \textbf{Modified HMAC:} Altered HMAC value---correctly rejected
    \item \textbf{Missing HMAC:} HMAC field removed---correctly rejected
\end{enumerate}

All integrity checks passed, demonstrating robust tamper protection.

\section{Performance Evaluation}

\subsection{Single File Scan Performance}

Single file scan times were measured across various file sizes:

\begin{table}[h]
\centering
\caption{Single File Scan Performance}
\label{tab:single_scan}
\begin{tabular}{@{}rccc@{}}
\toprule
\textbf{File Size} & \textbf{Hash Time (ms)} & \textbf{Lookup (ms)} & \textbf{Total (ms)} \\
\midrule
1 KB & 2 & 1 & 3 \\
100 KB & 5 & 1 & 6 \\
1 MB & 15 & 1 & 16 \\
10 MB & 85 & 1 & 86 \\
100 MB & 820 & 1 & 821 \\
500 MB & 4,100 & 1 & 4,101 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item Hash calculation time scales linearly with file size
    \item Signature lookup time remains constant (O(1) hash table)
    \item Files under 10 MB scan in under 100ms
    \item Chunked reading prevents memory issues with large files
\end{itemize}

\subsection{Directory Scan Performance}

Directory scanning performance with varying file counts:

\begin{table}[h]
\centering
\caption{Directory Scan Performance}
\label{tab:dir_scan}
\begin{tabular}{@{}rccc@{}}
\toprule
\textbf{File Count} & \textbf{Total Size} & \textbf{Scan Time (s)} & \textbf{Files/Second} \\
\midrule
100 & 50 MB & 0.8 & 125 \\
500 & 250 MB & 3.5 & 143 \\
1,000 & 500 MB & 6.8 & 147 \\
5,000 & 2.5 GB & 38.2 & 131 \\
10,000 & 5 GB & 82.5 & 121 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item Consistent throughput of 120-150 files per second
    \item Performance scales linearly with file count
    \item I/O becomes the bottleneck for large directories
\end{itemize}

\subsection{API Performance Under Load}

Backend API performance was tested with concurrent requests:

\begin{table}[h]
\centering
\caption{API Performance Under Load}
\label{tab:api_load}
\begin{tabular}{@{}rcccc@{}}
\toprule
\textbf{Concurrent} & \textbf{Requests/s} & \textbf{Avg (ms)} & \textbf{P95 (ms)} & \textbf{P99 (ms)} \\
\midrule
1 & 85 & 12 & 15 & 18 \\
10 & 320 & 31 & 45 & 58 \\
25 & 480 & 52 & 78 & 95 \\
50 & 520 & 96 & 145 & 180 \\
100 & 490 & 204 & 350 & 450 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item Maximum throughput of approximately 520 requests/second
    \item P95 latency remains under 200ms up to 50 concurrent users
    \item FastAPI's async capabilities handle concurrent requests efficiently
\end{itemize}

\subsection{Memory Usage}

Memory consumption was monitored during various operations:

\begin{table}[h]
\centering
\caption{Memory Usage by Component}
\label{tab:memory}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Component} & \textbf{Idle (MB)} & \textbf{Peak (MB)} \\
\midrule
Desktop CLI & 25 & 45 \\
Backend API & 65 & 120 \\
Backend + 1000 signatures & 68 & 125 \\
Web Frontend & 85 & 150 \\
Mobile App & 75 & 140 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item Desktop CLI has minimal memory footprint
    \item Chunked file reading prevents memory spikes for large files
    \item Signature database uses efficient in-memory storage
\end{itemize}

\section{Detection Accuracy}

\subsection{True Positive Rate}

Detection accuracy for known malware samples:

\begin{table}[h]
\centering
\caption{Detection Accuracy for Known Malware}
\label{tab:detection}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Malware Category} & \textbf{Samples} & \textbf{Detected} & \textbf{Rate} \\
\midrule
EICAR Test Files & 4 & 4 & 100\% \\
Trojan Signatures & 6 & 6 & 100\% \\
Ransomware Signatures & 5 & 5 & 100\% \\
Backdoor Signatures & 3 & 3 & 100\% \\
Worm Signatures & 2 & 2 & 100\% \\
Spyware Signatures & 2 & 2 & 100\% \\
Adware Signatures & 2 & 2 & 100\% \\
PUP Signatures & 1 & 1 & 100\% \\
\midrule
\textbf{Total} & \textbf{25} & \textbf{25} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} For known malware with matching signatures, MalGuard achieves 100\% detection rate. This is expected for signature-based detection where exact hash matches are performed.

\subsection{False Positive Rate}

Testing with legitimate files to assess false positive rate:

\begin{table}[h]
\centering
\caption{False Positive Testing}
\label{tab:false_positive}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{File Category} & \textbf{Files Tested} & \textbf{False Positives} & \textbf{FP Rate} \\
\midrule
Windows System Files & 100 & 0 & 0\% \\
Office Documents & 50 & 0 & 0\% \\
PDF Files & 50 & 0 & 0\% \\
Image Files & 100 & 0 & 0\% \\
Executables (clean) & 75 & 0 & 0\% \\
Installer Files & 25 & 0 & 0\% \\
\midrule
\textbf{Total} & \textbf{400} & \textbf{0} & \textbf{0\%} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} Zero false positives were observed. This is inherent to exact hash matching---only files with exact SHA-256 match to known malware are flagged.

\subsection{YARA Rule Detection}

YARA rules were tested for pattern-based detection:

\begin{table}[h]
\centering
\caption{YARA Rule Detection Results}
\label{tab:yara}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Rule Name} & \textbf{Test Files} & \textbf{Detected} & \textbf{Comments} \\
\midrule
EICAR\_Test\_File & 4 & 4 & EICAR string pattern \\
Suspicious\_PowerShell & 5 & 4 & 1 FN (obfuscated) \\
Ransomware\_Extensions & 3 & 3 & File extension patterns \\
Registry\_Persistence & 3 & 3 & Registry modification strings \\
Packed\_Executable & 2 & 2 & UPX/packer indicators \\
\bottomrule
\end{tabular}
\end{table}

YARA rules complement hash-based detection by identifying behavioral patterns in files that may not have known signatures.

\subsection{Detection Limitations}

As a signature-based system, MalGuard has inherent limitations:

\begin{enumerate}
    \item \textbf{Zero-Day Malware:} Cannot detect previously unknown malware without signatures
    \item \textbf{Polymorphic Malware:} Each variant requires a separate signature
    \item \textbf{Hash Collisions:} Theoretically possible but practically infeasible with SHA-256 \cite{stevens2017}
    \item \textbf{Packed/Obfuscated Files:} May evade YARA rules designed for unpacked code
\end{enumerate}

\section{Cross-Platform Compatibility}

\subsection{Desktop CLI Compatibility}

The Desktop CLI was tested across multiple operating systems:

\begin{table}[h]
\centering
\caption{Desktop CLI Platform Compatibility}
\label{tab:cli_compat}
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Platform} & \textbf{Version} & \textbf{Scan} & \textbf{YARA} & \textbf{Quarantine} & \textbf{Status} \\
\midrule
Windows 11 & 23H2 & \checkmark & \checkmark & \checkmark & Full Support \\
Windows 10 & 22H2 & \checkmark & \checkmark & \checkmark & Full Support \\
Ubuntu & 22.04 LTS & \checkmark & \checkmark & \checkmark & Full Support \\
Ubuntu & 20.04 LTS & \checkmark & \checkmark & \checkmark & Full Support \\
macOS & Sonoma 14 & \checkmark & \checkmark & \checkmark & Full Support \\
macOS & Ventura 13 & \checkmark & \checkmark & \checkmark & Full Support \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} Full compatibility achieved across all major desktop platforms with Python 3.8+.

\subsection{Web Frontend Compatibility}

Browser compatibility testing results:

\begin{table}[h]
\centering
\caption{Web Frontend Browser Compatibility}
\label{tab:web_compat}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Browser} & \textbf{Version} & \textbf{Status} & \textbf{Notes} \\
\midrule
Google Chrome & 120 & Full Support & Primary development browser \\
Mozilla Firefox & 121 & Full Support & All features working \\
Microsoft Edge & 120 & Full Support & Chromium-based \\
Safari & 17 & Full Support & WebKit rendering \\
Opera & 105 & Full Support & Chromium-based \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Mobile App Compatibility}

Mobile application testing across devices:

\begin{table}[h]
\centering
\caption{Mobile App Platform Compatibility}
\label{tab:mobile_compat}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Platform} & \textbf{Version} & \textbf{Status} & \textbf{Notes} \\
\midrule
Android & 13 (API 33) & Full Support & Pixel 6 Pro tested \\
Android & 12 (API 31) & Full Support & Samsung S21 tested \\
Android & 11 (API 30) & Full Support & OnePlus 8 tested \\
iOS & 17.0 & Full Support & iPhone 14 tested \\
iOS & 16.0 & Full Support & iPhone 13 tested \\
iOS & 15.0 & Full Support & iPhone 12 tested \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding:} React Native/Expo provides consistent behavior across iOS and Android platforms with minimal platform-specific code.

\section{Comparison with Existing Tools}

\subsection{Feature Comparison}

Comprehensive feature comparison with leading alternatives:

\begin{table}[h]
\centering
\caption{Feature Comparison with Existing Tools}
\label{tab:feature_comp}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Feature} & \textbf{MalGuard} & \textbf{ClamAV} & \textbf{VirusTotal} & \textbf{Norton} \\
\midrule
Open Source & \checkmark & \checkmark & $\times$ & $\times$ \\
Free & \checkmark & \checkmark & Partial & $\times$ \\
Desktop CLI & \checkmark & \checkmark & $\times$ & \checkmark \\
Web Interface & \checkmark & $\times$ & \checkmark & Limited \\
Mobile App & \checkmark & $\times$ & $\times$ & \checkmark \\
REST API & \checkmark & $\times$ & \checkmark & $\times$ \\
Custom Signatures & \checkmark & \checkmark & $\times$ & $\times$ \\
YARA Support & \checkmark & \checkmark & \checkmark & $\times$ \\
Quarantine & \checkmark & $\times$ & N/A & \checkmark \\
Offline Operation & \checkmark & \checkmark & $\times$ & \checkmark \\
Cross-Platform & \checkmark & Partial & N/A & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Performance Comparison}

Single file scan performance comparison (1 MB file):

\begin{table}[h]
\centering
\caption{Performance Comparison (1 MB Test File)}
\label{tab:perf_comp}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Tool} & \textbf{Scan Time (ms)} & \textbf{Memory (MB)} \\
\midrule
MalGuard & 16 & 25 \\
ClamAV (clamscan) & 2,500 & 180 \\
VirusTotal API & 3,000+ & N/A \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Note:} ClamAV's higher scan time is due to its much larger signature database (millions of signatures). VirusTotal time includes network latency for API calls.

\subsection{Advantages of MalGuard}

Based on comparative analysis, MalGuard offers several advantages:

\begin{enumerate}
    \item \textbf{Unified Platform:} Single solution for desktop, web, and mobile---unlike ClamAV (server-focused) or VirusTotal (web-only)
    
    \item \textbf{Complete Openness:} Fully open-source with educational documentation, unlike commercial alternatives
    
    \item \textbf{API-First Design:} RESTful API enables integration with existing security infrastructure
    
    \item \textbf{Customization:} Full control over signatures and YARA rules for targeted use cases
    
    \item \textbf{Lightweight:} Minimal resource requirements compared to full antivirus suites
    
    \item \textbf{Offline Capability:} Desktop CLI operates without network connectivity
\end{enumerate}

\subsection{Limitations Compared to Commercial Solutions}

MalGuard is not a replacement for comprehensive security suites:

\begin{enumerate}
    \item \textbf{Smaller Signature Database:} 25 sample signatures vs. millions in commercial solutions
    \item \textbf{No Real-Time Protection:} Currently lacks file system monitoring
    \item \textbf{No Behavioral Analysis:} Does not sandbox or analyze runtime behavior
    \item \textbf{Manual Updates:} Signatures must be manually updated or synced
\end{enumerate}

\section{User Interface Evaluation}

\subsection{Desktop CLI Usability}

The CLI interface was evaluated for usability:

\begin{itemize}
    \item \textbf{Color-Coded Output:} Red for threats, green for clean---intuitive visual feedback
    \item \textbf{JSON Mode:} Machine-readable output for automation and scripting
    \item \textbf{Help System:} Comprehensive --help for all commands
    \item \textbf{Exit Codes:} Standard exit codes (0=success, 1=error, 2=threat) for script integration
\end{itemize}

\subsection{Web Interface Usability}

The web frontend provides:

\begin{itemize}
    \item \textbf{Drag-and-Drop Upload:} Intuitive file selection
    \item \textbf{Real-Time Results:} Immediate feedback after scan
    \item \textbf{Responsive Design:} Works on desktop and tablet browsers
    \item \textbf{Dashboard:} At-a-glance statistics and recent detections
\end{itemize}

\subsection{Mobile App Usability}

The mobile application offers:

\begin{itemize}
    \item \textbf{Native File Picker:} Platform-appropriate file selection
    \item \textbf{Alert Notifications:} Immediate notification on threat detection
    \item \textbf{Simple Interface:} Minimal, focused UI for mobile use
\end{itemize}

\section{Discussion}

\subsection{Achievement of Objectives}

Reviewing the objectives stated in Chapter 1:

\begin{table}[h]
\centering
\caption{Objectives Achievement Summary}
\label{tab:objectives}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Objective} & \textbf{Status} & \textbf{Evidence} \\
\midrule
SHA-256 signature detection & Achieved & 100\% detection rate \\
YARA rule integration & Achieved & 8 rules functional \\
Desktop CLI & Achieved & Windows/macOS/Linux support \\
Backend API & Achieved & 20+ endpoints operational \\
Web Frontend & Achieved & All browsers supported \\
Mobile App & Achieved & iOS/Android compatible \\
HMAC database protection & Achieved & Tamper detection verified \\
Quarantine system & Achieved & Full functionality \\
Scan history & Achieved & Logging operational \\
\bottomrule
\end{tabular}
\end{table}

All primary and secondary objectives have been successfully achieved.

\subsection{Strengths of the Implementation}

Key strengths demonstrated through testing:

\begin{enumerate}
    \item \textbf{Performance:} Fast scanning with low resource usage
    \item \textbf{Reliability:} Zero crashes or data corruption during testing
    \item \textbf{Accuracy:} 100\% detection for known threats, 0\% false positives
    \item \textbf{Portability:} Successful operation across all target platforms
    \item \textbf{Security:} HMAC protection prevents database tampering
    \item \textbf{Extensibility:} Modular design allows easy feature additions
\end{enumerate}

\subsection{Areas for Improvement}

Testing revealed areas for future enhancement:

\begin{enumerate}
    \item \textbf{Signature Coverage:} Expand from 25 to thousands of signatures
    \item \textbf{Update Mechanism:} Implement automatic signature updates
    \item \textbf{Real-Time Monitoring:} Add file system watcher capability
    \item \textbf{UI Polish:} Additional UX improvements for mobile app
    \item \textbf{Documentation:} Expand inline code documentation
\end{enumerate}

\section{Summary}

This chapter presented comprehensive testing and evaluation of MalGuard. Functional testing verified all features including scanning, signature management, quarantine, and API endpoints. Performance benchmarks demonstrated efficient operation with scan rates of 120+ files per second and API throughput of 500+ requests per second. Detection testing confirmed 100\% accuracy for known signatures with zero false positives. Cross-platform compatibility was verified on Windows, macOS, Linux, multiple browsers, and iOS/Android devices. Comparison with existing tools highlighted MalGuard's unique position as a unified, open-source, cross-platform solution while acknowledging limitations compared to comprehensive commercial suites.
